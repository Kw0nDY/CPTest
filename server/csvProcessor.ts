import csvParser from 'csv-parser';
import { Readable } from 'stream';
import { pipeline } from 'stream/promises';

// ğŸ¯ ëŒ€ìš©ëŸ‰ CSV íŒŒì¼ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°

export interface CSVProcessOptions {
  maxRows?: number; // ìµœëŒ€ ì²˜ë¦¬ í–‰ ìˆ˜ (ë©”ëª¨ë¦¬ ì œí•œ)
  batchSize?: number; // ë°°ì¹˜ ì²˜ë¦¬ í¬ê¸°
  skipFirstRow?: boolean; // í—¤ë” ê±´ë„ˆë›°ê¸°
}

export interface CSVProcessResult {
  headers: string[];
  data: any[];
  rowCount: number;
  truncated: boolean;
  processingTime: number;
}

/**
 * ëŒ€ìš©ëŸ‰ CSV íŒŒì¼ì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
 * 89MB+ íŒŒì¼ì—ì„œ ìŠ¤íƒ ì˜¤ë²„í”Œë¡œìš° ë°©ì§€
 */
export async function processLargeCSV(
  csvContent: string, 
  options: CSVProcessOptions = {}
): Promise<CSVProcessResult> {
  const startTime = Date.now();
  const {
    maxRows = 5000, // ê¸°ë³¸ 5000í–‰ ì œí•œ (ë©”ëª¨ë¦¬ ë³´í˜¸)
    batchSize = 100,
    skipFirstRow = true
  } = options;

  const results: any[] = [];
  let headers: string[] = [];
  let rowCount = 0;
  let truncated = false;

  try {
    // í…ìŠ¤íŠ¸ë¥¼ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë©”ëª¨ë¦¬ ë¶€ë‹´ ê°ì†Œ
    const stream = Readable.from([csvContent]);
    
    // í—¤ë” ì¶”ì¶œì„ ìœ„í•œ Promise
    let headersResolved = false;
    
    await pipeline(
      stream,
      csvParser(),
      async function* (source) {
        for await (const chunk of source) {
          // ì²« ë²ˆì§¸ ì²­í¬ì—ì„œ í—¤ë” ì¶”ì¶œ
          if (!headersResolved) {
            headers = Object.keys(chunk);
            headersResolved = true;
            console.log(`ğŸ“Š CSV í—¤ë” ê°ì§€: ${headers.join(', ')}`);
          }

          rowCount++;

          // ë©”ëª¨ë¦¬ ë³´í˜¸: ìµœëŒ€ í–‰ ìˆ˜ ì œí•œ
          if (rowCount <= maxRows) {
            results.push(chunk);
            
            // ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì§„í–‰ ìƒí™© ë¡œê¹…
            if (rowCount % batchSize === 0) {
              console.log(`ğŸ”„ CSV ì²˜ë¦¬ ì§„í–‰: ${rowCount}í–‰ ì™„ë£Œ`);
            }
          } else {
            truncated = true;
            console.log(`âš ï¸ CSV íŒŒì¼ í¬ê¸° ì œí•œ: ${maxRows}í–‰ì—ì„œ ì²˜ë¦¬ ì¤‘ë‹¨ (ì „ì²´ ${rowCount}í–‰ ì¤‘)`);
            break;
          }

          yield chunk;
        }
      }
    );

    const processingTime = Date.now() - startTime;
    
    console.log(`âœ… CSV ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì™„ë£Œ: ${results.length}í–‰ ì²˜ë¦¬ë¨ (${processingTime}ms)`);
    
    return {
      headers,
      data: results,
      rowCount: results.length,
      truncated,
      processingTime
    };

  } catch (error) {
    console.error('âŒ CSV ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì˜¤ë¥˜:', error);
    
    // Fallback: ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì‘ì€ ë°ì´í„°ë§Œ ì²˜ë¦¬
    console.log('ğŸ”„ Fallback ëª¨ë“œ: ì†Œê·œëª¨ ë°ì´í„° ì²˜ë¦¬ ì‹œë„');
    return await processFallbackCSV(csvContent, options);
  }
}

/**
 * Fallback ì²˜ë¦¬: ì‘ì€ íŒŒì¼ìš© (1MB ì´í•˜)
 */
async function processFallbackCSV(
  csvContent: string, 
  options: CSVProcessOptions
): Promise<CSVProcessResult> {
  const startTime = Date.now();
  const { maxRows = 1000 } = options;

  try {
    // íŒŒì¼ í¬ê¸° í™•ì¸
    const fileSizeKB = Buffer.byteLength(csvContent, 'utf8') / 1024;
    console.log(`ğŸ“ CSV íŒŒì¼ í¬ê¸°: ${fileSizeKB.toFixed(2)} KB`);

    if (fileSizeKB > 1024) {
      throw new Error('íŒŒì¼ì´ ë„ˆë¬´ í¼: ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ í•„ìš”');
    }

    const lines = csvContent.split('\n').filter(line => line.trim() !== '');
    
    if (lines.length === 0) {
      throw new Error('ë¹ˆ CSV íŒŒì¼');
    }

    // í—¤ë” ì¶”ì¶œ
    const headers = lines[0].split(',').map(h => h.trim().replace(/"/g, ''));
    
    // ë°ì´í„° íŒŒì‹± (ì œí•œëœ í–‰ë§Œ)
    const dataLines = lines.slice(1, Math.min(lines.length, maxRows + 1));
    const results = dataLines.map(line => {
      const values = line.split(',').map(v => v.trim().replace(/"/g, ''));
      const row: any = {};
      headers.forEach((header, index) => {
        const value = values[index] || '';
        const numValue = parseFloat(value);
        row[header] = isNaN(numValue) ? value : numValue;
      });
      return row;
    });

    const processingTime = Date.now() - startTime;
    const truncated = lines.length > maxRows + 1;

    console.log(`âœ… Fallback CSV ì²˜ë¦¬ ì™„ë£Œ: ${results.length}í–‰ (${processingTime}ms)`);

    return {
      headers,
      data: results,
      rowCount: results.length,
      truncated,
      processingTime
    };

  } catch (error) {
    console.error('âŒ Fallback CSV ì²˜ë¦¬ ì˜¤ë¥˜:', error);
    throw error;
  }
}

/**
 * CSV íŒŒì¼ ì²­í¬ ì²˜ë¦¬ê¸° (ë©”ëª¨ë¦¬ ì ˆì•½í˜•)
 */
export class CSVChunkProcessor {
  private batchSize: number;
  private maxMemoryMB: number;
  
  constructor(batchSize = 100, maxMemoryMB = 50) {
    this.batchSize = batchSize;
    this.maxMemoryMB = maxMemoryMB;
  }

  async processInChunks(
    csvContent: string,
    processor: (batch: any[]) => Promise<void>
  ): Promise<{ totalRows: number; chunksProcessed: number }> {
    
    const stream = Readable.from([csvContent]);
    let batch: any[] = [];
    let totalRows = 0;
    let chunksProcessed = 0;
    const batchSize = this.batchSize;
    const maxMemoryMB = this.maxMemoryMB;

    await pipeline(
      stream,
      csvParser(),
      async function* (source) {
        for await (const row of source) {
          batch.push(row);
          totalRows++;

          if (batch.length >= batchSize) {
            await processor(batch);
            chunksProcessed++;
            batch = []; // ë©”ëª¨ë¦¬ í•´ì œ
            
            // ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬
            if (process.memoryUsage().heapUsed / 1024 / 1024 > maxMemoryMB) {
              console.warn(`âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì´ˆê³¼: ${maxMemoryMB}MB ì œí•œ`);
              break;
            }
          }

          yield row;
        }

        // ë§ˆì§€ë§‰ ë°°ì¹˜ ì²˜ë¦¬
        if (batch.length > 0) {
          await processor(batch);
          chunksProcessed++;
        }
      }
    );

    return { totalRows, chunksProcessed };
  }
}