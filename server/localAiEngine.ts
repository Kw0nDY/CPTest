import OpenAI from "openai";

/**
 * ğŸ¯ ë¡œì»¬ AI ì²˜ë¦¬ ì—”ì§„ - ì™¸ë¶€ Flowise API ì˜ì¡´ì„± ì œê±°
 * 
 * ì£¼ìš” ê¸°ëŠ¥:
 * - OpenAI APIë¥¼ í†µí•œ ë¡œì»¬ AI ì²˜ë¦¬ 
 * - Fallback ë©”ì»¤ë‹ˆì¦˜ìœ¼ë¡œ ì™¸ë¶€ API ì¥ì•  ëŒ€ì‘
 * - ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°ì´í„° ì²˜ë¦¬
 * - ì—ëŸ¬ ë³µêµ¬ ë° ì¬ì‹œë„ ë¡œì§
 */

export interface AIProcessingOptions {
  maxTokens?: number;
  temperature?: number;
  model?: string;
  contextLimit?: number;
  enableFallback?: boolean;
}

export interface AIProcessingResult {
  response: string;
  tokensUsed: number;
  processingTime: number;
  dataSource: 'local' | 'openai' | 'fallback';
  confidence: number;
  metadata?: {
    model: string;
    promptLength: number;
    dataRows: number;
  };
}

export class LocalAIEngine {
  private openai: OpenAI | null = null;
  private fallbackResponses: Map<string, string> = new Map();
  private isInitialized = false;

  constructor() {
    this.initializeFallbackResponses();
  }

  /**
   * AI ì—”ì§„ ì´ˆê¸°í™”
   */
  async initialize(apiKey?: string): Promise<boolean> {
    try {
      // 1. OpenAI API ì„¤ì • ì‹œë„
      const key = apiKey || process.env.OPENAI_API_KEY;
      if (key) {
        this.openai = new OpenAI({ apiKey: key });
        
        // API í‚¤ í…ŒìŠ¤íŠ¸
        await this.testConnection();
        console.log('âœ… OpenAI API ì—°ê²° ì„±ê³µ');
        this.isInitialized = true;
        return true;
      }
      
      console.warn('âš ï¸ OpenAI API í‚¤ê°€ ì—†ìŒ - Fallback ëª¨ë“œë¡œ ë™ì‘');
      this.isInitialized = true;
      return false;
    } catch (error) {
      console.error('âŒ AI ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
      console.log('ğŸ”„ Fallback ëª¨ë“œë¡œ ì „í™˜');
      this.isInitialized = true;
      return false;
    }
  }

  /**
   * OpenAI API ì—°ê²° í…ŒìŠ¤íŠ¸
   */
  private async testConnection(): Promise<void> {
    if (!this.openai) throw new Error('OpenAI not initialized');
    
    await this.openai.chat.completions.create({
      model: 'gpt-5', // the newest OpenAI model is "gpt-5" which was released August 7, 2025. do not change this unless explicitly requested by the user
      messages: [{ role: 'user', content: 'Hello' }],
      max_tokens: 10
    });
  }

  /**
   * ë©”ì¸ AI ì²˜ë¦¬ í•¨ìˆ˜ - ë°ì´í„° ë¶„ì„ ë° ì§ˆë¬¸ ì‘ë‹µ
   * ğŸ¯ AI ëª¨ë¸ë³„ ë°ì´í„° ê²©ë¦¬ ì§€ì›
   */
  async processQuery(
    userMessage: string,
    uploadedData: any[] = [],
    options: AIProcessingOptions = {},
    modelId?: string
  ): Promise<AIProcessingResult> {
    const startTime = Date.now();
    
    if (!this.isInitialized) {
      await this.initialize();
    }

    const {
      maxTokens = 2000,
      temperature = 0.7,
      model = 'gpt-5', // the newest OpenAI model is "gpt-5" which was released August 7, 2025. do not change this unless explicitly requested by the user
      contextLimit = 4000,
      enableFallback = true
    } = options;

    try {
      // ğŸ¯ ëª¨ë¸ë³„ ë°ì´í„° ê²©ë¦¬ ë¡œê¹…
      if (modelId) {
        console.log(`ğŸ”’ AI ëª¨ë¸ ${modelId}ì— ëŒ€í•œ ê²©ë¦¬ëœ ë°ì´í„° ì²˜ë¦¬: ${uploadedData.length}ê°œ ë ˆì½”ë“œ`);
      }
      
      // 1. OpenAI API ì²˜ë¦¬ ì‹œë„
      if (this.openai) {
        console.log('ğŸ¤– OpenAI ë¡œì»¬ ì²˜ë¦¬ ì‹œì‘');
        return await this.processWithOpenAI(userMessage, uploadedData, {
          maxTokens,
          temperature,
          model,
          contextLimit,
          startTime
        }, modelId);
      }

      // 2. Fallback ì²˜ë¦¬
      if (enableFallback) {
        console.log('ğŸ”„ Fallback ëª¨ë“œë¡œ ì²˜ë¦¬');
        return this.processFallback(userMessage, uploadedData, startTime);
      }

      throw new Error('AI ì²˜ë¦¬ ì—”ì§„ì´ ì‚¬ìš© ë¶ˆê°€');

    } catch (error) {
      console.error('âŒ AI ì²˜ë¦¬ ì˜¤ë¥˜:', error);
      
      // 3. ì—ëŸ¬ ì‹œ Fallback
      if (enableFallback) {
        console.log('ğŸ›¡ï¸ ì—ëŸ¬ ë³µêµ¬: Fallback ëª¨ë“œë¡œ ì „í™˜');
        return this.processFallback(userMessage, uploadedData, startTime);
      }
      
      throw error;
    }
  }

  /**
   * OpenAI APIë¥¼ í†µí•œ ì²˜ë¦¬
   * ğŸ¯ AI ëª¨ë¸ë³„ ë°ì´í„° ê²©ë¦¬ ì§€ì›
   */
  private async processWithOpenAI(
    userMessage: string,
    uploadedData: any[],
    config: {
      maxTokens: number;
      temperature: number;
      model: string;
      contextLimit: number;
      startTime: number;
    },
    modelId?: string
  ): Promise<AIProcessingResult> {
    if (!this.openai) throw new Error('OpenAI not initialized');

    // ë°ì´í„° ìš”ì•½ (ì»¨í…ìŠ¤íŠ¸ ì œí•œ ëŒ€ì‘)
    const dataContext = this.summarizeData(uploadedData, config.contextLimit);
    
    // í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ëª¨ë¸ë³„ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€)
    const systemPrompt = this.createSystemPrompt(dataContext, modelId);
    const prompt = this.createUserPrompt(userMessage, dataContext, modelId);
    
    console.log(`ğŸ“Š ë°ì´í„° ì»¨í…ìŠ¤íŠ¸: ${dataContext.rowCount}ê°œ í–‰, ${prompt.length}ì í”„ë¡¬í”„íŠ¸`);

    try {
      const completion = await this.openai.chat.completions.create({
        model: config.model,
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: prompt }
        ],
        max_tokens: config.maxTokens,
        temperature: config.temperature,
        response_format: { type: "json_object" },
      });

      const response = completion.choices[0].message.content || '';
      const tokensUsed = completion.usage?.total_tokens || 0;
      const processingTime = Date.now() - config.startTime;

      console.log(`âœ… OpenAI ì²˜ë¦¬ ì™„ë£Œ: ${tokensUsed} í† í°, ${processingTime}ms`);

      // JSON ì‘ë‹µ íŒŒì‹±
      let parsedResponse;
      try {
        parsedResponse = JSON.parse(response);
        return {
          response: parsedResponse.answer || parsedResponse.response || response,
          tokensUsed,
          processingTime,
          dataSource: 'openai',
          confidence: parsedResponse.confidence || 0.8,
          metadata: {
            model: config.model,
            promptLength: prompt.length,
            dataRows: uploadedData.length
          }
        };
      } catch (parseError) {
        // JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
        return {
          response,
          tokensUsed,
          processingTime,
          dataSource: 'openai',
          confidence: 0.7,
          metadata: {
            model: config.model,
            promptLength: prompt.length,
            dataRows: uploadedData.length
          }
        };
      }

    } catch (apiError: any) {
      console.error('OpenAI API ì˜¤ë¥˜:', apiError);
      
      // API í•œë„ ì´ˆê³¼ë‚˜ ì„œë¹„ìŠ¤ ì˜¤ë¥˜ ì‹œ fallback
      if (apiError.status === 429 || apiError.status >= 500) {
        console.log('ğŸ”„ API í•œë„/ì„œë¹„ìŠ¤ ì˜¤ë¥˜ - Fallbackìœ¼ë¡œ ì „í™˜');
        throw new Error('API_LIMIT_OR_SERVICE_ERROR');
      }
      
      throw apiError;
    }
  }

  /**
   * Fallback ì²˜ë¦¬ (ë¡œì»¬ ê·œì¹™ ê¸°ë°˜)
   */
  private processFallback(
    userMessage: string,
    uploadedData: any[],
    startTime: number
  ): AIProcessingResult {
    const processingTime = Date.now() - startTime;
    
    // í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„
    const analysis = this.analyzeKeywords(userMessage, uploadedData);
    
    return {
      response: analysis.response,
      tokensUsed: 0,
      processingTime,
      dataSource: 'fallback',
      confidence: analysis.confidence,
      metadata: {
        model: 'fallback-rules',
        promptLength: userMessage.length,
        dataRows: uploadedData.length
      }
    };
  }

  /**
   * ë°ì´í„° ìš”ì•½ (ë©”ëª¨ë¦¬ ë° ì»¨í…ìŠ¤íŠ¸ ì œí•œ ëŒ€ì‘)
   * ğŸ¯ ëŒ€ìš©ëŸ‰ íŒŒì¼ ìŠ¤ë§ˆíŠ¸ ë¶„ì„ ì§€ì›
   */
  private summarizeData(data: any[], maxContext: number, message?: string): {
    summary: string;
    rowCount: number;
    columns: string[];
    sampleData: any[];
    metadata?: any;
  } {
    if (!data || data.length === 0) {
      return {
        summary: 'ì—…ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.',
        rowCount: 0,
        columns: [],
        sampleData: []
      };
    }

    // ì „ì²´ ë°ì´í„° ì²­í¬ ì²˜ë¦¬ (ëŒ€ìš©ëŸ‰ íŒŒì¼ ì§€ì›)
    const chunkItems = data.filter(item => item.type === 'full_data_chunks');
    const metadataItems = data.filter(item => item.type === 'large_file_metadata');
    const actualData = data.filter(item => !item.type || (item.type !== 'large_file_metadata' && item.type !== 'full_data_chunks'));
    
    let summary = '';
    let columns: string[] = [];
    let rowCount = actualData.length;
    let sampleData: any[] = [];
    
    if (chunkItems.length > 0) {
      // ì „ì²´ ë°ì´í„° ì²­í¬ ì²˜ë¦¬ëœ ê²½ìš°
      const chunkData = chunkItems[0];
      columns = chunkData.columns || [];
      rowCount = chunkData.totalRows;
      
      // ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì²­í¬ ì„ íƒ (í‚¤ì›Œë“œ ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰)
      const relevantChunks = this.selectRelevantChunks(chunkData.chunks, message || '');
      
      // ì„ íƒëœ ì²­í¬ì—ì„œ ëŒ€í‘œ ë°ì´í„° ì¶”ì¶œ
      sampleData = this.extractRepresentativeData(relevantChunks, 50);
      
      summary = `ì „ì²´ ë°ì´í„°ì…‹: ${rowCount}ê°œ í–‰ (${chunkData.totalChunks}ê°œ ì²­í¬ë¡œ ì™„ì „ ì²˜ë¦¬), ${columns.length}ê°œ ì—´. ì§ˆë¬¸ ê´€ë ¨ ${relevantChunks.length}ê°œ ì²­í¬ì—ì„œ ${sampleData.length}ê°œ ëŒ€í‘œ ë°ì´í„° ë¶„ì„`;
      
    } else if (metadataItems.length > 0) {
      // ê¸°ì¡´ ìƒ˜í”Œë§ ë°©ì‹
      const meta = metadataItems[0];
      columns = meta.columns || [];
      summary = `ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹: ì›ë³¸ ${meta.totalRows}ê°œ í–‰ â†’ ë¶„ì„ìš© ${meta.samplesExtracted}ê°œ ìƒ˜í”Œ ì¶”ì¶œ, ${columns.length}ê°œ ì—´ (${columns.slice(0, 10).join(', ')}${columns.length > 10 ? '...' : ''})`;
      rowCount = meta.totalRows;
      
      sampleData = actualData.slice(0, 15).map(item => {
        if (item.data && typeof item.data === 'object') {
          return item.data;
        }
        return item;
      });
    } else {
      // ì¼ë°˜ ë°ì´í„° ì²˜ë¦¬
      const firstRow = actualData[0];
      if (firstRow && typeof firstRow === 'object') {
        if (firstRow.data && typeof firstRow.data === 'object') {
          columns = Object.keys(firstRow.data);
        } else {
          columns = Object.keys(firstRow);
        }
      }
      summary = `ë°ì´í„°ì…‹: ${actualData.length}ê°œ í–‰, ${columns.length}ê°œ ì—´ (${columns.join(', ')})`;
      
      sampleData = actualData.slice(0, 15).map(item => {
        if (item.data && typeof item.data === 'object') {
          return item.data;
        }
        return item;
      });
    }
    
    return {
      summary,
      rowCount,
      columns,
      sampleData,
      metadata: metadataItems.length > 0 ? metadataItems[0] : (chunkItems.length > 0 ? chunkItems[0] : null)
    };
  }

  /**
   * ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì²­í¬ ì„ íƒ (ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰)
   */
  private selectRelevantChunks(chunks: any[], message: string): any[] {
    if (!message || !chunks || chunks.length === 0) {
      // ì§ˆë¬¸ì´ ì—†ìœ¼ë©´ ëª¨ë“  ì²­í¬ì—ì„œ ê· ë“±í•˜ê²Œ ì„ íƒ
      return chunks.slice(0, Math.min(5, chunks.length));
    }
    
    const messageWords = message.toLowerCase().split(/\s+/);
    const scoredChunks = chunks.map(chunk => {
      let score = 0;
      const summary = chunk.summary;
      
      // í‚¤ì›Œë“œ ë§¤ì¹­ ìŠ¤ì½”ì–´ë§
      messageWords.forEach(word => {
        // ë°°ì¹˜ ê´€ë ¨ ì§ˆë¬¸
        if ((word.includes('ë°°ì¹˜') || word.includes('batch')) && summary.uniqueBatches?.length > 0) score += 10;
        
        // ìš´ì˜ì ê´€ë ¨ ì§ˆë¬¸
        if ((word.includes('ìš´ì˜ì') || word.includes('operator')) && summary.uniqueOperators?.length > 0) score += 10;
        
        // OEE ê´€ë ¨ ì§ˆë¬¸
        if ((word.includes('oee') || word.includes('íš¨ìœ¨')) && summary.oeeRange) score += 10;
        
        // ìƒì‚°ì„± ê´€ë ¨ ì§ˆë¬¸
        if ((word.includes('ìƒì‚°') || word.includes('production') || word.includes('rate')) && summary.productionRange) score += 10;
        
        // ì˜¨ë„ ê´€ë ¨ ì§ˆë¬¸
        if ((word.includes('ì˜¨ë„') || word.includes('temp')) && summary.tempRange) score += 10;
        
        // ë‹¨ê³„/ìƒíƒœ ê´€ë ¨ ì§ˆë¬¸
        if ((word.includes('ë‹¨ê³„') || word.includes('phase') || word.includes('ìƒíƒœ')) && summary.uniquePhases?.length > 0) score += 10;
        
        // ì§€ì—­ ê´€ë ¨ ì§ˆë¬¸
        if ((word.includes('ì§€ì—­') || word.includes('site') || word.includes('ì†¡ë„') || word.includes('songdo')) && summary.uniqueSites?.length > 0) score += 10;
        
        // ìˆ«ì ê´€ë ¨ ì§ˆë¬¸ (íŠ¹ì • ë²”ìœ„)
        const numberMatch = word.match(/\d+/);
        if (numberMatch && summary.idRange) {
          const num = parseInt(numberMatch[0]);
          const [min, max] = summary.idRange.split('-').map(Number);
          if (num >= min && num <= max) score += 15;
        }
      });
      
      return { chunk, score };
    });
    
    // ìŠ¤ì½”ì–´ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ ì²­í¬ ì„ íƒ
    const sortedChunks = scoredChunks.sort((a, b) => b.score - a.score);
    const selectedChunks = sortedChunks.slice(0, Math.min(8, chunks.length)).map(item => item.chunk);
    
    // ìŠ¤ì½”ì–´ê°€ ì—†ìœ¼ë©´ ê· ë“± ë¶„í¬ë¡œ ì„ íƒ
    if (selectedChunks.every(chunk => scoredChunks.find(sc => sc.chunk === chunk)?.score === 0)) {
      const interval = Math.max(1, Math.floor(chunks.length / 5));
      return chunks.filter((_, index) => index % interval === 0).slice(0, 5);
    }
    
    return selectedChunks;
  }

  /**
   * ì„ íƒëœ ì²­í¬ì—ì„œ ëŒ€í‘œ ë°ì´í„° ì¶”ì¶œ
   */
  private extractRepresentativeData(chunks: any[], maxSamples: number): any[] {
    if (!chunks || chunks.length === 0) return [];
    
    const allData = [];
    const samplesPerChunk = Math.max(1, Math.floor(maxSamples / chunks.length));
    
    chunks.forEach(chunk => {
      if (chunk.data && Array.isArray(chunk.data)) {
        // ê° ì²­í¬ì—ì„œ ê· ë“±í•˜ê²Œ ìƒ˜í”Œ ì¶”ì¶œ
        const chunkSamples = chunk.data.filter((_, index) => 
          index % Math.max(1, Math.floor(chunk.data.length / samplesPerChunk)) === 0
        ).slice(0, samplesPerChunk);
        
        allData.push(...chunkSamples);
      }
    });
    
    return allData.slice(0, maxSamples);
  }

  /**
   * ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
   * ğŸ¯ AI ëª¨ë¸ë³„ ì»¨í…ìŠ¤íŠ¸ ì§€ì›
   */
  private createSystemPrompt(dataContext: any, modelId?: string): string {
    let prompt = `ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì—…ë¡œë“œëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ì •í™•íˆ ë‹µë³€í•˜ì„¸ìš”.

ë°ì´í„° ì •ë³´:
- ${dataContext.summary}
- ì»¬ëŸ¼: ${dataContext.columns.join(', ')}`;

    if (modelId) {
      prompt += `\n\nğŸ”’ ë³´ì•ˆ ì •ì±…: ì´ ë°ì´í„°ëŠ” AI ëª¨ë¸ ${modelId}ì—ë§Œ ì ‘ê·¼ì´ í—ˆìš©ëœ ê²©ë¦¬ëœ ë°ì´í„°ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ëª¨ë¸ì´ë‚˜ ì‹œìŠ¤í…œê³¼ ê³µìœ í•˜ì§€ ë§ˆì„¸ìš”.`;
    }

    prompt += `\n\nJSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{
  "answer": "ë¶„ì„ ê²°ê³¼ ë‹µë³€",
  "confidence": 0.8,
  "key_insights": ["ì£¼ìš” ì¸ì‚¬ì´íŠ¸1", "ì¸ì‚¬ì´íŠ¸2"],
  "data_summary": "ë°ì´í„° ìš”ì•½"
}`;

    return prompt;
  }

  /**
   * ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ìƒì„±
   * ğŸ¯ AI ëª¨ë¸ë³„ ë°ì´í„° ì¶”ì  ì§€ì›
   */
  private createUserPrompt(userMessage: string, dataContext: any, modelId?: string): string {
    let prompt = `ì§ˆë¬¸: ${userMessage}\n\n`;
    
    if (modelId) {
      prompt += `ğŸ¯ AI ëª¨ë¸: ${modelId}\n`;
    }
    
    if (dataContext.sampleData.length > 0) {
      prompt += `ìƒ˜í”Œ ë°ì´í„°:\n`;
      prompt += JSON.stringify(dataContext.sampleData.slice(0, 3), null, 2);
      prompt += `\n\nì´ ${dataContext.rowCount}ê°œ í–‰ ì¤‘ ì¼ë¶€ì…ë‹ˆë‹¤.`;
    }
    
    return prompt;
  }

  /**
   * í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„ (Fallbackìš©)
   */
  private analyzeKeywords(userMessage: string, data: any[]): {
    response: string;
    confidence: number;
  } {
    const message = userMessage.toLowerCase();
    
    // ë°ì´í„° ê¸°ë³¸ ì •ë³´
    const dataInfo = data.length > 0 ? 
      `ë°ì´í„°ì…‹: ${data.length}ê°œ í–‰, ${Object.keys(data[0] || {}).length}ê°œ ì—´` :
      'ì—…ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.';
    
    // í‚¤ì›Œë“œ íŒ¨í„´ ë¶„ì„
    if (message.includes('ë¶„ì„') || message.includes('ìš”ì•½')) {
      return {
        response: `${dataInfo}\n\nê°„ë‹¨í•œ ë¶„ì„ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. ë” ìì„¸í•œ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” AI ê¸°ëŠ¥ì„ í™œì„±í™”í•´ì£¼ì„¸ìš”.`,
        confidence: 0.6
      };
    }
    
    if (message.includes('ê°œìˆ˜') || message.includes('ìˆ˜ëŸ‰')) {
      return {
        response: `ë°ì´í„° ê°œìˆ˜: ${data.length}ê°œ`,
        confidence: 0.8
      };
    }
    
    if (message.includes('ì»¬ëŸ¼') || message.includes('í•„ë“œ')) {
      const columns = data.length > 0 ? Object.keys(data[0]) : [];
      return {
        response: `ì»¬ëŸ¼: ${columns.join(', ')} (ì´ ${columns.length}ê°œ)`,
        confidence: 0.8
      };
    }
    
    // ê¸°ë³¸ ì‘ë‹µ
    return {
      response: `${dataInfo}\n\ní˜„ì¬ AI ê¸°ëŠ¥ì´ ì œí•œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë” ì •í™•í•œ ë‹µë³€ì„ ìœ„í•´ AI ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.`,
      confidence: 0.4
    };
  }

  /**
   * Fallback ì‘ë‹µ ì´ˆê¸°í™”
   */
  private initializeFallbackResponses(): void {
    this.fallbackResponses.set('data_analysis', 'ë°ì´í„°ë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤. AI ê¸°ëŠ¥ì„ í™œì„±í™”í•˜ë©´ ë” ìì„¸í•œ ë¶„ì„ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.');
    this.fallbackResponses.set('data_summary', 'ë°ì´í„° ìš”ì•½ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.');
    this.fallbackResponses.set('error', 'ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
  }

  /**
   * ì—”ì§„ ìƒíƒœ í™•ì¸
   */
  getStatus(): {
    isInitialized: boolean;
    hasOpenAI: boolean;
    canProcess: boolean;
  } {
    return {
      isInitialized: this.isInitialized,
      hasOpenAI: this.openai !== null,
      canProcess: this.isInitialized
    };
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
export const localAI = new LocalAIEngine();