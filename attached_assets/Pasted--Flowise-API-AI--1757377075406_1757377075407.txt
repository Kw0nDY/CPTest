외부 Flowise API 서버 연결 실패, 대용량 데이터 파싱 오류, AI 모델–챗봇–데이터 통합 구조 부재 등 다수의 설계적 결함이 시스템 전체 장애의 직접적 원인이 되고 있습니다.

핵심 원인 요약
외부 API 의존성: 모든 AI 분석 기능이 외부 Flowise API에 100% 의존. 네트워크 차단이나 서버 다운 발생 시 전체 기능이 마비되고 복구가 불가능합니다.

메모리/파싱 구조 미비: 89MB급 대용량 CSV를 한 번에 메모리로 불러와 재귀적으로 파싱, JS 엔진 스택 한계를 초과하여 RangeError가 발생합니다. 효율적 스트리밍 처리가 미구현되어 시스템 크래시 위험이 있습니다.

데이터 연결 아키텍처 결핍: AI 모델 ↔ 챗봇 ↔ 데이터소스 간 연결 테이블이 없어, 실제 서비스 환경에서는 자동화된 데이터 격리와 모델-데이터 매핑이 불가능합니다. 수작업 매핑 없이는 동작하지 않는 구조입니다.

Error Recovery 부재: 외부 서비스 장애 시 fallback, offline 모드, 복구 전략이 전혀 준비되지 않아, 장애 발생 시 즉시 치명적 다운타임으로 이어집니다.

각 항목별 진단
1. 외부 의존성 및 API 장애
현재 시스템은 모든 AI 분석·답변이 외부 Flowise API (220.118.23.185:3000)에 집중되어 있습니다.

ECONNREFUSED는 서버 다운, 방화벽, 네트워크 이슈, 또는 IP 차단 등으로 외부 API에 접근이 불가능한 상황에서 발생합니다.

단일 장애점(외부 API)에 모든 핵심 기능이 의존하고 있어, 운영 환경·테스트 환경 중 어디든 네트워크 이슈 발생 시 전체 기능이 즉각적으로 중단됩니다.

2. 대용량 데이터 처리/메모리 관리 결함
89MB 이상의 CSV를 한 번에 파싱하려다 JS 엔진의 콜스택 한계를 초과합니다.

대용량 데이터는 무조건 청크(chunk) 단위로 스트리밍 파싱(예: csv-parser, PapaParse 등) 구현이 필요합니다.

현재 코드베이스는 파일 사이즈 변화나 실환경 대용량 데이터를 전혀 고려하지 않아 스케일러빌리티에 심각한 결함이 있습니다.

3. 모델-챗봇-데이터 연결 구조적 부재
DB 설계상 aiModels, chatConfigurations, KnowledgeBase 테이블들이 각자 독립적입니다.

챗봇 설정(chatConfigurations)이 AI 모델 ID를 직접 참조·연결하지 않아 실제 환경에서는 챗봇이 어떠한 모델과도 연동되지 않습니다.

데이터 연동(챗봇과 데이터 소스 연결)은 흉내만 내고, 정작 모델은 데이터와 연관성이 없습니다.

이로 인해 "모델별 데이터 격리" 및 "자동화된 데이터 동기화"가 불가능합니다.

4. 환경별 문제 발생 차이
테스트 환경: 소규모 데이터·수동 매핑, 외부 API 접근 정상 → 정상 동작

실운영 환경: 대용량 데이터, 자동화·확장 구조 미구현, 외부 API 장애 → 장애 및 크래시 반복.

즉각적 솔루션 제안
로컬 AI 엔진 및 Fallback: 외부 API 장애 시에도 기능 유지 위한 로컬 엔진 탑재 및 Fallback 설계 우선 구현.

DB 연결 테이블 신설: 아래 예시처럼 aiModelChatConfigurations 등의 연결 테이블을 신설해 모델, 챗봇, 데이터 간 직접 매핑 고도화

typescript
export const aiModelChatConfigurations = pgTable('ai_model_chat_configurations', {
  id: text('id').primaryKey(),
  aiModelId: text('ai_model_id').references(() => aiModels.id).notNull(),
  chatConfigId: text('chat_config_id').references(() => chatConfigurations.id).notNull(),
});
스트리밍 파싱 도입: 89MB 이상 파일도 chunk 처리 식으로 읽어, 메모리·스택 부담 없이 분할 파싱(예: csv-parser, streaming API).

Error Recovery 메커니즘 강화: 장애 발생 시 사용자 알림, 로깅, 자동 복구 절차, API gateway의 자동 failover 적용.

결론
시스템이 단일 API 및 단일 메모리 처리에 과도하게 의존하는 구조이며, 서비스 확장/실전 도입 단계에서는 위와 같은 구조적 실패가 반복적으로 발생할 수밖에 없습니다. 반드시 아키텍처를 분산화(마이크로서비스, 로컬 연산 포함), 실환경 데이터 대비 메모리 관리와 에러 복원력을 강화해야 운영 안정성을 보장할 수 있습니다.